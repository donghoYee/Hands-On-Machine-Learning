{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0364ede",
   "metadata": {},
   "source": [
    "# NLP with RNN and Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b253d9c2",
   "metadata": {},
   "source": [
    "### shakespeare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec7c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n",
      "1130496/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77dae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any fur\n"
     ]
    }
   ],
   "source": [
    "print(len(shakespeare_text))\n",
    "print(shakespeare_text[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "759e9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71ae15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be2fbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e37f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "dataset_size = tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b4f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1115394\n"
     ]
    }
   ],
   "source": [
    "print(max_id)\n",
    "print(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d75997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aadffd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-16 11:15:39.826903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:39.859292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:39.859478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:39.860046: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-16 11:15:39.860775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:39.860962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:39.861099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:40.207271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:40.207434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:40.207558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-16 11:15:40.207661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee672e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf40d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e79c44ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3078504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, y_batch:(tf.one_hot(X_batch, depth=max_id), y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2484ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ca9f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2,recurrent_dropout=0.2), # input shape is [None, max_id] because time_step size can be any!\n",
    "    keras.layers.LSTM(128, return_sequences=True,\n",
    "                     dropout=0.2,recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86920f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31368/31368 [==============================] - 8997s 287ms/step - loss: 1.4658\n",
      "Epoch 2/20\n",
      "24835/31368 [======================>.......] - ETA: 31:09 - loss: 1.3203"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31b944bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) -1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0da37405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n"
     ]
    }
   ],
   "source": [
    "X_new = preprocess([\"How are yo\"])\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "print(tokenizer.sequences_to_texts(y_pred + 1)[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3ceaf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model.predict(X_new)[0, -1:, :] # use last probability for getting next char!\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "931465b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, n_chars=50, temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29067dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In humblion by a mouth: sing gods\n",
      "my father, let us\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"I\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9560fc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for split data!!!!!\n",
    "batch_size=32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)# array_split splits the dataset into batch_size segments\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift = n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = (tf.data.Dataset.zip(tuple(datasets))).map(lambda *windows: tf.stack(windows))\n",
    "\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67033be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True, stateful=True, dropout=0.2, batch_input_shape=[batch_size, None, max_id]), # recurrnet_dropout=0.2), ## for hardware acceleration\n",
    "    keras.layers.LSTM(128, return_sequences=True, stateful=True, dropout=0.2), # recurrnet_dropout=0.2), ## for hardware acceleration\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation=\"softmax\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d99c8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0034fb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "313/313 [==============================] - 4s 8ms/step - loss: 1.4000\n",
      "Epoch 2/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3715\n",
      "Epoch 3/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3556\n",
      "Epoch 4/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3431\n",
      "Epoch 5/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3325\n",
      "Epoch 6/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3231\n",
      "Epoch 7/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3146\n",
      "Epoch 8/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.3068\n",
      "Epoch 9/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2996\n",
      "Epoch 10/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2929\n",
      "Epoch 11/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2867\n",
      "Epoch 12/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2808\n",
      "Epoch 13/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2752\n",
      "Epoch 14/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2699\n",
      "Epoch 15/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2648\n",
      "Epoch 16/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2600\n",
      "Epoch 17/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2554\n",
      "Epoch 18/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2510\n",
      "Epoch 19/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2468\n",
      "Epoch 20/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2428\n",
      "Epoch 21/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2388\n",
      "Epoch 22/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2351\n",
      "Epoch 23/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2314\n",
      "Epoch 24/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2279\n",
      "Epoch 25/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2245\n",
      "Epoch 26/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2211\n",
      "Epoch 27/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2179\n",
      "Epoch 28/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2148\n",
      "Epoch 29/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2117\n",
      "Epoch 30/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2087\n",
      "Epoch 31/200\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.2059\n",
      "Epoch 32/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2032\n",
      "Epoch 33/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.2004\n",
      "Epoch 34/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1978\n",
      "Epoch 35/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1951\n",
      "Epoch 36/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1925\n",
      "Epoch 37/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1901\n",
      "Epoch 38/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1877\n",
      "Epoch 39/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1852\n",
      "Epoch 40/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1830\n",
      "Epoch 41/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1805\n",
      "Epoch 42/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1783\n",
      "Epoch 43/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1760\n",
      "Epoch 44/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1739\n",
      "Epoch 45/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1721\n",
      "Epoch 46/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1696\n",
      "Epoch 47/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1677\n",
      "Epoch 48/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1655\n",
      "Epoch 49/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1635\n",
      "Epoch 50/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1615\n",
      "Epoch 51/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1596\n",
      "Epoch 52/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1578\n",
      "Epoch 53/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1558\n",
      "Epoch 54/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1544\n",
      "Epoch 55/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1525\n",
      "Epoch 56/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1506\n",
      "Epoch 57/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1487\n",
      "Epoch 58/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1479\n",
      "Epoch 59/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1457\n",
      "Epoch 60/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1454\n",
      "Epoch 61/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1428\n",
      "Epoch 62/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1415\n",
      "Epoch 63/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1397\n",
      "Epoch 64/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1386\n",
      "Epoch 65/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1366\n",
      "Epoch 66/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1360\n",
      "Epoch 67/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1343\n",
      "Epoch 68/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1322\n",
      "Epoch 69/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1305\n",
      "Epoch 70/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1295\n",
      "Epoch 71/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1277\n",
      "Epoch 72/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1264\n",
      "Epoch 73/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1254\n",
      "Epoch 74/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1239\n",
      "Epoch 75/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1224\n",
      "Epoch 76/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1214\n",
      "Epoch 77/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1205\n",
      "Epoch 78/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1196\n",
      "Epoch 79/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1177\n",
      "Epoch 80/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1166\n",
      "Epoch 81/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1156\n",
      "Epoch 82/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1142\n",
      "Epoch 83/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1129\n",
      "Epoch 84/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1121\n",
      "Epoch 85/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1122\n",
      "Epoch 86/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1108\n",
      "Epoch 87/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1100\n",
      "Epoch 88/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1105\n",
      "Epoch 89/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1090\n",
      "Epoch 90/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1072\n",
      "Epoch 91/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1066\n",
      "Epoch 92/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1056\n",
      "Epoch 93/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1047\n",
      "Epoch 94/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1035\n",
      "Epoch 95/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1029\n",
      "Epoch 96/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1022\n",
      "Epoch 97/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1013\n",
      "Epoch 98/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1006\n",
      "Epoch 99/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.1000\n",
      "Epoch 100/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0997\n",
      "Epoch 101/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0992\n",
      "Epoch 102/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0978\n",
      "Epoch 103/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0975\n",
      "Epoch 104/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0974\n",
      "Epoch 105/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0969\n",
      "Epoch 106/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0955\n",
      "Epoch 107/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0945\n",
      "Epoch 108/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0940\n",
      "Epoch 109/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0940\n",
      "Epoch 110/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0940\n",
      "Epoch 111/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0932\n",
      "Epoch 112/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0930\n",
      "Epoch 113/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0931\n",
      "Epoch 114/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0922\n",
      "Epoch 115/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0912\n",
      "Epoch 116/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0928\n",
      "Epoch 117/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0919\n",
      "Epoch 118/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0899\n",
      "Epoch 119/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0892\n",
      "Epoch 120/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0889\n",
      "Epoch 121/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0886\n",
      "Epoch 122/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0867\n",
      "Epoch 123/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0863\n",
      "Epoch 124/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0887\n",
      "Epoch 125/200\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.0851\n",
      "Epoch 126/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0838\n",
      "Epoch 127/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0830\n",
      "Epoch 128/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0817\n",
      "Epoch 129/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0820\n",
      "Epoch 130/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0816\n",
      "Epoch 131/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0810\n",
      "Epoch 132/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0809\n",
      "Epoch 133/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0811\n",
      "Epoch 134/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0802\n",
      "Epoch 135/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0796\n",
      "Epoch 136/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0804\n",
      "Epoch 137/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0797\n",
      "Epoch 138/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0787\n",
      "Epoch 139/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0780\n",
      "Epoch 140/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0781\n",
      "Epoch 141/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0783\n",
      "Epoch 142/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0869\n",
      "Epoch 143/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0819\n",
      "Epoch 144/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0782\n",
      "Epoch 145/200\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 1.0778\n",
      "Epoch 146/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0767\n",
      "Epoch 147/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0756\n",
      "Epoch 148/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0743\n",
      "Epoch 149/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0750\n",
      "Epoch 150/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0732\n",
      "Epoch 151/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0729\n",
      "Epoch 152/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0723\n",
      "Epoch 153/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0711\n",
      "Epoch 154/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0715\n",
      "Epoch 155/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0712\n",
      "Epoch 156/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0705\n",
      "Epoch 157/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0703\n",
      "Epoch 158/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0706\n",
      "Epoch 159/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0706\n",
      "Epoch 160/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0705\n",
      "Epoch 161/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0694\n",
      "Epoch 162/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0693\n",
      "Epoch 163/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0679\n",
      "Epoch 164/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0675\n",
      "Epoch 165/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0675\n",
      "Epoch 166/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0675\n",
      "Epoch 167/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0688\n",
      "Epoch 168/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0695\n",
      "Epoch 169/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0679\n",
      "Epoch 170/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0686\n",
      "Epoch 171/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0674\n",
      "Epoch 172/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0671\n",
      "Epoch 173/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0673\n",
      "Epoch 174/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0660\n",
      "Epoch 175/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0679\n",
      "Epoch 176/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0682\n",
      "Epoch 177/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0661\n",
      "Epoch 178/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0668\n",
      "Epoch 179/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0657\n",
      "Epoch 180/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0647\n",
      "Epoch 181/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0644\n",
      "Epoch 182/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0653\n",
      "Epoch 183/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0662\n",
      "Epoch 184/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0650\n",
      "Epoch 185/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0634\n",
      "Epoch 186/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0628\n",
      "Epoch 187/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0643\n",
      "Epoch 188/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0623\n",
      "Epoch 189/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0622\n",
      "Epoch 190/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0618\n",
      "Epoch 191/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0609\n",
      "Epoch 192/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0610\n",
      "Epoch 193/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0610\n",
      "Epoch 194/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0614\n",
      "Epoch 195/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0608\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0598\n",
      "Epoch 197/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0594\n",
      "Epoch 198/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0607\n",
      "Epoch 199/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0604\n",
      "Epoch 200/200\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 1.0591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb264fde200>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "model.fit(dataset, epochs=200, callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe7c2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 복사하여 여러 배치 처리\n",
    "stateless_model = keras.models.Sequential([ \n",
    "    keras.layers.LSTM(128, return_sequences=True, input_shape=[None, max_id]), # a stateless model!! input shape's batch_size is not important\n",
    "    keras.layers.LSTM(128, return_sequences=True), # dropout is not necessary!!\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5430ed7",
   "metadata": {},
   "source": [
    "가중치를 복사하려면 먼저 (가중치를 만들기 위해) 모델을 빌드합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a479969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.build(tf.TensorShape([None, None, max_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9334f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model.set_weights(model.get_weights()) #이것만 부르면 다 됨!! -> stat 신경 쓸 필요 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35fa9836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im: be sorrow by my own\n",
      "as i did practise your thit\n"
     ]
    }
   ],
   "source": [
    "model = stateless_model\n",
    "print(complete_text(\"i\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f7431",
   "metadata": {},
   "source": [
    "## IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcda315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 1s 0us/step\n",
      "17473536/17464789 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()\n",
    "X_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e87efdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()} #items returns the word and id tokens!\n",
    "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    id_to_word[id_] = token\n",
    "print(\" \".join([id_to_word[id_] for id_ in X_train[0][:20]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e29ae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2e0b25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\">, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'>, <tf.Tensor: shape=(), dtype=int64, numpy=0>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursued, but when no \"men\" are around, they become the pursuers of a 14 year old boy. And the boy becomes a man really fast (we should all be so lucky at this age!). He then gets up the courage to pursue his true love.'>, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 10:19:00.207690: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for data in datasets[\"train\"].take(5):\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50515e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch) # 단어 조각이 나옴\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch # 패딩 씌워서 작은 문장 처리!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73c1f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘 사전 구축\n",
    "from collections import Counter\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy())) # numpy for real-value, list to make it into list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bbf7ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214316), (b'the', 61137), (b'a', 38562)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3dacce0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54104"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbffc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많이 등장한 단어 10000개만 사용!\n",
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common()[:vocab_size]] # Counter-> most_common returns sorted array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9fdf050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing word dictionary\n",
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64) # same as range\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids) # give ids for preallocated words -> give keys to vocabs\n",
    "num_oov_buckets = 1000 # number of unknown words\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9b3985c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=int64, numpy=array([[10729,     7,  6018]])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"dongho is Fantastic\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1cb04123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch\n",
    "\n",
    "train_set = datasets[\"train\"].batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98d585ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, input_shape=[None]), # input shape is None because it will be N * 300 -> will be determined\n",
    "    keras.layers.LSTM(256, return_sequences=True),\n",
    "    keras.layers.LSTM(256),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11f8013d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 15s 17ms/step - loss: 0.5404 - accuracy: 0.7290\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.3603 - accuracy: 0.8527\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.2420 - accuracy: 0.9125\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.1844 - accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.1665 - accuracy: 0.9444\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1353 - accuracy: 0.9548\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1206 - accuracy: 0.9596\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0997 - accuracy: 0.9678\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 15s 20ms/step - loss: 0.0771 - accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.0686 - accuracy: 0.9785\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.0664 - accuracy: 0.9804\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.0630 - accuracy: 0.9796\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0538 - accuracy: 0.9839\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.0445 - accuracy: 0.9863\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0476 - accuracy: 0.9852\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0412 - accuracy: 0.9877\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.0410 - accuracy: 0.9880\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0433 - accuracy: 0.9874\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.0424 - accuracy: 0.9864\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.0448 - accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639b5c1",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f5d1a1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 16s 15ms/step - loss: 0.5278 - accuracy: 0.7375\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.3458 - accuracy: 0.8588\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.2262 - accuracy: 0.9178\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.1730 - accuracy: 0.9386\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.1336 - accuracy: 0.9531\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0957 - accuracy: 0.9689\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0761 - accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0770 - accuracy: 0.9743\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0607 - accuracy: 0.9786\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0568 - accuracy: 0.9803\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0499 - accuracy: 0.9834\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0473 - accuracy: 0.9840\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0321 - accuracy: 0.9887\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0301 - accuracy: 0.9894\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0251 - accuracy: 0.9914\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0210 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0168 - accuracy: 0.9949\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 14s 18ms/step - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0129 - accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# use mask_zero = True !\n",
    "embed_size = 256\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size, input_shape=[None],\n",
    "                          mask_zero=True), # input shape is None because it will be N * 300 -> will be determined\n",
    "    keras.layers.LSTM(256, return_sequences=True),\n",
    "    keras.layers.LSTM(256),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3582636",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = datasets[\"test\"].batch(32).map(preprocess)\n",
    "test_set = test_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2cd769cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 7s 7ms/step - loss: 1.5791 - accuracy: 0.7292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.579132080078125, 0.7292400002479553]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64e86fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직점 마스킹을 처리!\n",
    "K = keras.backend\n",
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "z = keras.layers.Embedding(vocab_size+num_oov_buckets, embed_size)(inputs)\n",
    "z = keras.layers.LSTM(256, return_sequences=True)(z, mask=mask) # give mask like this!! dim between z and mask is different!\n",
    "z = keras.layers.LSTM(256)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "\n",
    "model = keras.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e05ddf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 18s 18ms/step - loss: 0.5486 - accuracy: 0.7240\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.3754 - accuracy: 0.8426\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.2420 - accuracy: 0.9116\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.1753 - accuracy: 0.9391\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.1401 - accuracy: 0.9520\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.1230 - accuracy: 0.9580\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0935 - accuracy: 0.9692\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0794 - accuracy: 0.9729\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0787 - accuracy: 0.9747\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0557 - accuracy: 0.9820\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0446 - accuracy: 0.9853\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0388 - accuracy: 0.9874\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0368 - accuracy: 0.9884\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0279 - accuracy: 0.9912\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 12s 16ms/step - loss: 0.0288 - accuracy: 0.9909\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0298 - accuracy: 0.9908\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0265 - accuracy: 0.9913\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 13s 17ms/step - loss: 0.0238 - accuracy: 0.9923\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 13s 16ms/step - loss: 0.0200 - accuracy: 0.9933\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 12s 15ms/step - loss: 0.0190 - accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1db1db",
   "metadata": {},
   "source": [
    "### Using Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c8b679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf hub!!\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model = keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                    dtype=tf.string, input_shape=[], output_shape=[50]), # returns one vector for one sentence!\n",
    "    keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ed4fc91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.5001 - accuracy: 0.7577\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4974 - accuracy: 0.7592\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4947 - accuracy: 0.7610\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4920 - accuracy: 0.7615\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4893 - accuracy: 0.7631\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4868 - accuracy: 0.7648\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4844 - accuracy: 0.7670\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4821 - accuracy: 0.7686\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4797 - accuracy: 0.7704\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4775 - accuracy: 0.7715\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4754 - accuracy: 0.7731\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4733 - accuracy: 0.7750\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4713 - accuracy: 0.7769\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4693 - accuracy: 0.7778\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4674 - accuracy: 0.7789\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4656 - accuracy: 0.7798\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4638 - accuracy: 0.7817\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4619 - accuracy: 0.7820\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4603 - accuracy: 0.7832\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.7838\n"
     ]
    }
   ],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "batch_size = 32\n",
    "train_set = datasets[\"train\"].batch(batch_size).prefetch(1)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c2e15",
   "metadata": {},
   "source": [
    "# Encoder-decoder Network for Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0d13f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "vocab_size = 100\n",
    "embed_size = 10\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32) # don't know the size of the sentence yet\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size) # initialize class ilke this!\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs) # use same embedding like this!\n",
    "\n",
    "encoder = keras.layers.LSTM(512, return_state=True) # return state!\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(512)\n",
    "output_layer = keras.layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer = output_layer)\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state, sequence_length=sequence_lengths)\n",
    "\n",
    "Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.Model(inputs=[encoder_inputs, decoder_inputs, sequence_lengths], outputs=[Y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4fe330a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "32/32 [==============================] - 2s 16ms/step - loss: 4.6055\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 4.6040\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "X = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
    "Y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
    "X_decoder = np.c_[np.zeros((1000, 1)), Y[:, :-1]]\n",
    "seq_lengths = np.full([1000], 15)\n",
    "\n",
    "history = model.fit([X, X_decoder, seq_lengths], Y, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd4024",
   "metadata": {},
   "source": [
    "### 양방향 순환 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1dd3ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True)) #이것만 하면 됨!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3d6d0",
   "metadata": {},
   "source": [
    "### 빔 검색"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26248a0d",
   "metadata": {},
   "source": [
    "```\n",
    "beam_width = 10\n",
    "decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
    "            cell=decoder_cell, beam_width=beam_width, output_layer=output_layer) # 훈련된걸 감쌈?\n",
    "decoder_initial_state = tfa.seq2seq.beam_search_decoder.tile_batch(\n",
    "            encoder_state, multiplier=beam_width)\n",
    "outputs, _, _ = decoder(embedding_decoder, start_tokens=start_tokens,end_token=endtoken, initial_state=decoder_initial_state\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16c21c",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860b5c2",
   "metadata": {},
   "source": [
    "```\n",
    "attention_mechanism = tfa.seq2seq.attention_wrapper.LuongAttention(\n",
    "    units, encoder_state, memory_sequence_length=encoder_sequence_length)\n",
    "attention_decoder_cell = tfa.seq2seq.attention_wrapper.AttentionWrapper(\n",
    "    decoder_cell, attention_mechanism, attention_layer_size=n_units)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e8880",
   "metadata": {},
   "source": [
    "* Visual Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a7e66",
   "metadata": {},
   "source": [
    "## Transformer : Attentions is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5810c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position encoding\n",
    "class PositionalEncoding(keras.layers.Layer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if max_dims % 2 == 1: max_dims+=1\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_embed = np.empty((1, max_steps, max_dims))\n",
    "        pos_embed[0, :, ::2] = np.sin(p / 10000 ** (2*i / max_dims)).T\n",
    "        pos_embed[0, :, 1::2] = np.cos(p / 10000 ** (2*i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_embed.astype(self.dtype))\n",
    "        pass\n",
    "    def call(self, inputs):\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]] # use broadcasting!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "47edbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layers of transformer\n",
    "embed_size = 512\n",
    "max_steps = 500\n",
    "vocab_size = 10000\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "embeddings =keras.layers.Embedding(vocab_size, embed_size) # share embedding layer!\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "positional_embedding = PositionalEncoding(max_steps, max_dims=embed_size) # share encoding layer!\n",
    "encoder_in = positional_embedding(encoder_embeddings)\n",
    "decoder_in = positional_embedding(decoder_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f11a401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트렌스포머의 나머지 부분\n",
    "Z = encoder_in\n",
    "for N in range(6):\n",
    "    Z = keras.layers.Attention(use_scale=True)([Z, Z])\n",
    "    \n",
    "encoder_outputs = Z\n",
    "\n",
    "Z = decoder_in\n",
    "for N in range(6):\n",
    "    Z = keras.layers.Attention(use_scale=True, causal=True)([Z, Z])\n",
    "    Z = keras.layers.Attention(use_scale=True)([Z, encoder_outputs])\n",
    "    \n",
    "outputs = keras.layers.TimeDistributed(keras.layers.Dense(vocab_size, activation=\"softmax\"))(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139ddee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HOML]",
   "language": "python",
   "name": "conda-env-HOML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
