{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a65942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae469c",
   "metadata": {},
   "source": [
    "## 8.\n",
    "_연습문제: 호크라이터와 슈미트후버는 LSTM에 관한 [논문](https://homl.info/93)에서 임베딩된 레버 문법을 사용했습니다. 이는 ‘BPBTSXXVPSEPE’와 같은 문자열을 만드는 인공 문법입니다. 이 주제에 대한 제니 오어의 훌륭한 소개(https://homl.info/108)를 확인해보세요. 특정 임베딩된 레버 문법 하나를 선택하고(제니 오어의 페이지에 있는 것과 같은), 그다음에 문자열이 이 문법을 따르는지 아닌지 구별하는 RNN을 훈련해보세요. 먼저 문법에 맞는 문자열 50%와 그렇지 않은 문자열 50%를 담은 훈련 배치를 생성하는 함수를 만들어야 합니다._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df73be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_reber_grammar = [\n",
    "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
    "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
    "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
    "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
    "    [(\"X\", 3), (\"S\", 6)],\n",
    "    [(\"P\", 4), (\"V\", 6)],\n",
    "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
    "\n",
    "embedded_reber_grammar = [\n",
    "    [(\"B\", 1)],\n",
    "    [(\"T\", 2), (\"P\", 3)],\n",
    "    [(default_reber_grammar, 4)],\n",
    "    [(default_reber_grammar, 5)],\n",
    "    [(\"T\", 6)],\n",
    "    [(\"P\", 6)],\n",
    "    [(\"E\", None)]]\n",
    "\n",
    "def generate_string(grammar):\n",
    "    state = 0\n",
    "    output = []\n",
    "    while state is not None:\n",
    "        index = np.random.randint(len(grammar[state]))\n",
    "        production, state = grammar[state][index]\n",
    "        if isinstance(production, list):\n",
    "            production = generate_string(grammar=production)\n",
    "        output.append(production)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a43e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_string(default_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e723083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE BPBTXXVPSEPE BTBTXXVVETE BPBPVVEPE BPBPVVEPE BPBTSXSEPE BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_string(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a9471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "\n",
    "def generate_corrupted_string(grammer, chars=POSSIBLE_CHARS):\n",
    "    good_string = generate_string(grammer)\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(chars) - set(good_char))) # change charactor\n",
    "\n",
    "    return good_string[:index] + bad_char + good_string[index+1 :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22c5f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTTTPPXTVPXTTVPSETE BPBTXEEPE BPBPTVVVEPE BPBTSSSSXSETE BPTTXSEPE BTBPVPXTTTTTTEVETE BPBTXXSVEPE BSBPTTVPSETE BPBXVVEPE BEBTXSETE BPBPVPSXPE BTBPVVVETE BPBTSXSETE BPBPTTTPTTTTTVPSEPE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for _ in range(25):\n",
    "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2204fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84a4b5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 4, 4, 6, 6, 5, 5, 1, 4, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_ids(\"BTTTXXVVETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71bc12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with 50% right, 50% wrong\n",
    "\n",
    "def generate_dataset(size):\n",
    "    good_strings = [string_to_ids(generate_string(embedded_reber_grammar))\n",
    "                    for _ in range(size // 2)] # list in a list\n",
    "    bad_strings = [string_to_ids(generate_corrupted_string(embedded_reber_grammar))\n",
    "                   for _ in range(size // 2)]\n",
    "    all_strings = good_strings + bad_strings\n",
    "    X = tf.ragged.constant(all_strings, ragged_rank=1) # TENSOR WITH NON-UNIFORM RANK\n",
    "    y = np.array([[1.0] for _ in range(len(good_strings))] + [[0.0] for _ in range(len(bad_strings))])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "503aa962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 19:16:53.904984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:53.929450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:53.929628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:53.930255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-28 19:16:53.930939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:53.931092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:53.931228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:54.285361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:54.285528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:54.285652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-28 19:16:54.285757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, y_train = generate_dataset(10000)\n",
    "X_valid, y_valid = generate_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "380c69be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       "array([0, 4, 0, 2, 4, 4, 4, 5, 2, 6, 4, 5, 2, 6, 4, 4, 5, 2, 3, 1, 4, 1],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c18d9e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac444dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongho/.local/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/lstm/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 20), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/lstm/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/313 [>.............................] - ETA: 0s - loss: 0.6929 - accuracy: 0.4926  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 19:24:53.926879: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 4ms/step - loss: 0.6933 - accuracy: 0.5022 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6929 - accuracy: 0.5003 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.4715\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6898 - accuracy: 0.5308 - val_loss: 0.6890 - val_accuracy: 0.5640\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6856 - accuracy: 0.5544 - val_loss: 0.6843 - val_accuracy: 0.4650\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6790 - accuracy: 0.5678 - val_loss: 0.6768 - val_accuracy: 0.6110\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.6690 - accuracy: 0.5873 - val_loss: 0.6686 - val_accuracy: 0.5420\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.6590 - accuracy: 0.5962 - val_loss: 0.6581 - val_accuracy: 0.6680\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.6450 - accuracy: 0.6289 - val_loss: 0.6511 - val_accuracy: 0.5035\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6162 - accuracy: 0.6762 - val_loss: 0.6045 - val_accuracy: 0.5445\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5554 - accuracy: 0.7150 - val_loss: 0.5390 - val_accuracy: 0.7340\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5048 - accuracy: 0.7533 - val_loss: 0.4945 - val_accuracy: 0.7560\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.4707 - accuracy: 0.7768 - val_loss: 0.4563 - val_accuracy: 0.7855\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.4454 - accuracy: 0.7905 - val_loss: 0.4133 - val_accuracy: 0.8335\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4033 - accuracy: 0.8244 - val_loss: 0.4013 - val_accuracy: 0.8330\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3921 - accuracy: 0.8290 - val_loss: 0.3727 - val_accuracy: 0.8370\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.3748 - accuracy: 0.8385 - val_loss: 0.3544 - val_accuracy: 0.8415\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.3600 - accuracy: 0.8443 - val_loss: 0.3158 - val_accuracy: 0.8655\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8608 - val_loss: 0.6347 - val_accuracy: 0.7410\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3311 - accuracy: 0.8624 - val_loss: 0.2508 - val_accuracy: 0.9095\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.8938 - val_loss: 0.3347 - val_accuracy: 0.8610\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2200 - accuracy: 0.9247 - val_loss: 0.1529 - val_accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2344 - accuracy: 0.9127 - val_loss: 0.1435 - val_accuracy: 0.9575\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1972 - accuracy: 0.9329 - val_loss: 0.1139 - val_accuracy: 0.9680\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1175 - accuracy: 0.9667 - val_loss: 0.1055 - val_accuracy: 0.9710\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1623 - accuracy: 0.9501 - val_loss: 0.1460 - val_accuracy: 0.9580\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3517 - accuracy: 0.8645 - val_loss: 0.2460 - val_accuracy: 0.9110\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.8901 - val_loss: 0.2361 - val_accuracy: 0.9115\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1742 - accuracy: 0.9450 - val_loss: 0.0976 - val_accuracy: 0.9755\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2470 - accuracy: 0.9149 - val_loss: 0.1656 - val_accuracy: 0.9425\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.9658 - val_loss: 0.0969 - val_accuracy: 0.9765\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0789 - accuracy: 0.9784 - val_loss: 0.0609 - val_accuracy: 0.9810\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0613 - accuracy: 0.9822 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9903 - val_loss: 0.0351 - val_accuracy: 0.9915\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9854 - val_loss: 0.0291 - val_accuracy: 0.9955\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.0213 - val_accuracy: 0.9950\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9777 - val_loss: 0.0404 - val_accuracy: 0.9865\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.0134 - val_accuracy: 0.9965\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0124 - accuracy: 0.9972 - val_loss: 0.0104 - val_accuracy: 0.9970\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0091 - val_accuracy: 0.9985\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0041 - val_accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 9.7738e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 9.3015e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9945 - val_loss: 0.0288 - val_accuracy: 0.9930\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 9.7285e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9990\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 8.8631e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 8.1898e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 7.6457e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 7.1931e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 6.8293e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 6.4553e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 6.1528e-04 - accuracy: 1.0000 - val_loss: 9.8996e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 5.8738e-04 - accuracy: 1.0000 - val_loss: 9.6190e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 5.6139e-04 - accuracy: 1.0000 - val_loss: 9.6931e-04 - val_accuracy: 0.9995\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 5.4024e-04 - accuracy: 1.0000 - val_loss: 8.9885e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 5.2028e-04 - accuracy: 1.0000 - val_loss: 7.9414e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 5.0034e-04 - accuracy: 1.0000 - val_loss: 8.0397e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 4.8296e-04 - accuracy: 1.0000 - val_loss: 7.3115e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 4.6782e-04 - accuracy: 1.0000 - val_loss: 7.2767e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 4.5145e-04 - accuracy: 1.0000 - val_loss: 7.1195e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 4.3820e-04 - accuracy: 1.0000 - val_loss: 6.9608e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 4.2415e-04 - accuracy: 1.0000 - val_loss: 7.1099e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 4.1187e-04 - accuracy: 1.0000 - val_loss: 7.1723e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 4.0038e-04 - accuracy: 1.0000 - val_loss: 6.3215e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.8962e-04 - accuracy: 1.0000 - val_loss: 6.3619e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.7942e-04 - accuracy: 1.0000 - val_loss: 6.1845e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.6861e-04 - accuracy: 1.0000 - val_loss: 6.7587e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.6087e-04 - accuracy: 1.0000 - val_loss: 6.3575e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.5133e-04 - accuracy: 1.0000 - val_loss: 5.7874e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.4298e-04 - accuracy: 1.0000 - val_loss: 5.6669e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.3514e-04 - accuracy: 1.0000 - val_loss: 5.4875e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.2713e-04 - accuracy: 1.0000 - val_loss: 5.5525e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.2032e-04 - accuracy: 1.0000 - val_loss: 5.5423e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.1330e-04 - accuracy: 1.0000 - val_loss: 5.6277e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.0676e-04 - accuracy: 1.0000 - val_loss: 5.8219e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.0078e-04 - accuracy: 1.0000 - val_loss: 5.6227e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.9420e-04 - accuracy: 1.0000 - val_loss: 5.3576e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.8792e-04 - accuracy: 1.0000 - val_loss: 4.8337e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 2.8273e-04 - accuracy: 1.0000 - val_loss: 5.3640e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.7732e-04 - accuracy: 1.0000 - val_loss: 5.3934e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.7258e-04 - accuracy: 1.0000 - val_loss: 5.1250e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.6741e-04 - accuracy: 1.0000 - val_loss: 4.8447e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.6231e-04 - accuracy: 1.0000 - val_loss: 4.8088e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.5740e-04 - accuracy: 1.0000 - val_loss: 5.0281e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.5281e-04 - accuracy: 1.0000 - val_loss: 4.5933e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 2.4933e-04 - accuracy: 1.0000 - val_loss: 4.5349e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.4463e-04 - accuracy: 1.0000 - val_loss: 4.5962e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.4066e-04 - accuracy: 1.0000 - val_loss: 4.7828e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.3646e-04 - accuracy: 1.0000 - val_loss: 4.0743e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 2.3353e-04 - accuracy: 1.0000 - val_loss: 4.3575e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.2935e-04 - accuracy: 1.0000 - val_loss: 4.5354e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f496157fbb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size = 20\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True), # use ragged=True to use ragged tensors\n",
    "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
    "    keras.layers.LSTM(50),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9197d912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "레버 문자열일 추정 확률:\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 0.73%\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.99%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
    "X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n",
    "y_proba = model.predict(X_test)\n",
    "\n",
    "print()\n",
    "print(\"레버 문자열일 추정 확률:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcbdf5",
   "metadata": {},
   "source": [
    "## 9.\n",
    "_연습문제: 날짜 문자열 포맷을 변환하는 인코더-디코더 모델을 훈련하세요(예를 들어, ‘April 22, 2019’에서 ‘2019-04-22’로 바꿉니다)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5100af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "    \n",
    "    ordinals = np.random.randint(max_date - min_date, size = n_dates)+ min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "    \n",
    "    x = [MONTHS[dt.month -1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    \n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7d5b50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "September 20, 7075       7075-09-20               \n",
      "May 15, 8579             8579-05-15               \n",
      "January 11, 7103         7103-01-11               \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce99fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \"))) ### use set to ignore duplicate!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cb8eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71a34242",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65187af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars=INPUT_CHARS):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09129eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(x_example[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e5d330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(y_example[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "480cff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor() # use 0 as padding token!\n",
    "def create_dataset(n_dates):\n",
    "    x, y = random_dates(n_dates)\n",
    "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "99a86b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_train, Y_train = create_dataset(10000)\n",
    "X_valid, Y_valid = create_dataset(2000)\n",
    "X_test, Y_test = create_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9dcdd387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c769d44",
   "metadata": {},
   "source": [
    "### 첫 번째 버전: 기본적인 seq2seq 모델\n",
    "먼저 가장 간단한 모델을 시도해 보겠습니다: 입력 시퀀스가 먼저 (임베딩 층 뒤에 하나의 LSTM 층으로 구성된) 인코더를 통과하여 벡터로 출력됩니다. 그 다음 이 벡터가 (하나의 LSTM 층 뒤에 밀집 층으로 구성된) 디코더로 들어가 벡터의 시퀀스를 출력합니다. 각 벡터는 가능한 모든 출력 문자에 대한 추정 확률입니다.\n",
    "\n",
    "디코더는 시퀀스를 입력으로 기대하기 때문에 가능한 가장 긴 출력 시퀀스만큼 (인코더의 출력) 벡터를 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23a8d42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 4s 6ms/step - loss: 1.8045 - accuracy: 0.3551 - val_loss: 1.4062 - val_accuracy: 0.4743\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2313 - accuracy: 0.5484 - val_loss: 1.0980 - val_accuracy: 0.5980\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1665 - accuracy: 0.5862 - val_loss: 0.9322 - val_accuracy: 0.6582\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.1515 - accuracy: 0.5898 - val_loss: 0.9523 - val_accuracy: 0.6572\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8271 - accuracy: 0.6939 - val_loss: 0.6718 - val_accuracy: 0.7370\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.5898 - accuracy: 0.7658 - val_loss: 0.5229 - val_accuracy: 0.7843\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.5686 - accuracy: 0.7851 - val_loss: 0.4258 - val_accuracy: 0.8276\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3530 - accuracy: 0.8572 - val_loss: 0.3141 - val_accuracy: 0.8707\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2615 - accuracy: 0.9019 - val_loss: 0.2207 - val_accuracy: 0.9207\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2505 - accuracy: 0.9301 - val_loss: 0.1704 - val_accuracy: 0.9538\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9786 - val_loss: 0.0732 - val_accuracy: 0.9858\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9921 - val_loss: 0.0423 - val_accuracy: 0.9945\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9970 - val_loss: 0.0260 - val_accuracy: 0.9977\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9988 - val_loss: 0.0176 - val_accuracy: 0.9985\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.9242 - val_loss: 0.5184 - val_accuracy: 0.8317\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1723 - accuracy: 0.9622 - val_loss: 0.0671 - val_accuracy: 0.9949\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9987 - val_loss: 0.0276 - val_accuracy: 0.9990\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9997 - val_loss: 0.0158 - val_accuracy: 0.9992\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9997\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9998\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9998\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9999\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9999\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9999\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 8.2217e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 6.7608e-04 - accuracy: 1.0000 - val_loss: 8.5509e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 5.5606e-04 - accuracy: 1.0000 - val_loss: 7.0740e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.6009e-04 - accuracy: 1.0000 - val_loss: 5.9062e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.8105e-04 - accuracy: 1.0000 - val_loss: 5.0685e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.1742e-04 - accuracy: 1.0000 - val_loss: 4.3021e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.6462e-04 - accuracy: 1.0000 - val_loss: 3.4919e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.2124e-04 - accuracy: 1.0000 - val_loss: 2.9424e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8397e-04 - accuracy: 1.0000 - val_loss: 2.5349e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5375e-04 - accuracy: 1.0000 - val_loss: 2.1835e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.2872e-04 - accuracy: 1.0000 - val_loss: 1.7812e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0769e-04 - accuracy: 1.0000 - val_loss: 1.5234e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 9.0026e-05 - accuracy: 1.0000 - val_loss: 1.2732e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 7.5216e-05 - accuracy: 1.0000 - val_loss: 1.1136e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 6.2913e-05 - accuracy: 1.0000 - val_loss: 9.3552e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 5.3039e-05 - accuracy: 1.0000 - val_loss: 7.8912e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 4.4406e-05 - accuracy: 1.0000 - val_loss: 6.6459e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.7273e-05 - accuracy: 1.0000 - val_loss: 5.5729e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 3.1191e-05 - accuracy: 1.0000 - val_loss: 4.6869e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.6284e-05 - accuracy: 1.0000 - val_loss: 4.0381e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 2.2127e-05 - accuracy: 1.0000 - val_loss: 3.3741e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.8646e-05 - accuracy: 1.0000 - val_loss: 2.8750e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 32\n",
    "max_output_length = Y_train.shape[1]\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1, \n",
    "                           output_dim = embedding_size, \n",
    "                           input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True), #return sequence!\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder, \n",
    "    keras.layers.RepeatVector(max_output_length),# just repeat vector!\n",
    "    decoder\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, Y_train, epochs=50, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e396fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [\"\".join([(\"*\"+chars)[index] for index in sequence])\n",
    "            for sequence in ids] #\"*\" because output is added by 1\n",
    "                # join inputs a list of string!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2dbe91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_date_strs([\"September 17, 2009\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "752093c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f409f",
   "metadata": {},
   "source": [
    "하지만 (가장 긴 날짜에 해당하는) 길이가 18인 입력 문자열에서만 모델이 훈련되었기 때문에 짧은 시퀀스에서는 잘 동작하지 않습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c46a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4880b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-02\n",
      "1789-09-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023984e9",
   "metadata": {},
   "source": [
    "이런! 패딩을 사용해 훈련할 때와 동일한 길이의 시퀀스를 전달해야 할 것 같습니다. 이를 위해 헬퍼 함수를 작성해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a787914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = X_train.shape[1]\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]]) # tf.pad\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de2706a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3207bcd6",
   "metadata": {},
   "source": [
    "### 두 번째 버전: 디코더에서 쉬프트된 타깃 주입하기(티처 포싱(teacher forcing))\n",
    "디코더에세 인코더 출력 벡터를 단순히 반복한 것을 주입하는 대신 한 타임 스텝 오른쪽으로 이동된 타깃 시퀀스를 주입할 수 있습니다. 이렇게 하면 각 타임 스텝에서 디코더는 이전 타깃 문자가 무엇인지 알게 됩니다. 이는 더 복잡한 시퀀스-투-시퀀스 문제를 다루는데 도움이 됩니다.\n",
    "\n",
    "각 타깃 시퀀스의 첫 번째 출력 문자는 이전 문자가 없기 때문에 시퀀스 시작(start-of-sequence, sos)을 나타내는 새로운 토큰이 필요합니다.\n",
    "\n",
    "추론에서는 타깃을 알지 못하므로 디코더에게 무엇을 주입해야 할까요? sos 토큰을 시작해서 한 번에 하나의 문자를 예측하고 디코더에게 지금까지 예측한 모든 문자를 주입할 수 있습니다(나중에 이 노트북에서 더 자세히 알아 보겠습니다).\n",
    "\n",
    "하지만 디코더의 LSTM이 스텝마다 이전 타깃을 입력으로 기대한다면 인코더의 벡터 출력을 어떻게 전달할까요? 한가지 방법은 출력 벡터를 무시하는 것입니다. 그리고 대신 인코더의 LSTM 상태를 디코더의 LSTM의 초기 상태로 사용합니다(이렇게 하려면 인코더의 LSTM과 디코더의 LSTM 유닛 개수가 같아야 합니다).\n",
    "\n",
    "그럼 (훈련, 검증, 테스트를 위한) 디코더의 입력을 만들어 보죠. sos 토큰은 가능한 출력 문자의 마지막 ID + 1으로 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03ff8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "def shifted_output_sequences(Y):\n",
    "    sos_tokens = tf.fill(dims=(len(Y), 1), value = sos_id) # an array\n",
    "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1) # disgard last axis of Y!\n",
    "\n",
    "X_train_decoder = shifted_output_sequences(Y_train) # input the target!!\n",
    "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
    "X_test_decoder = shifted_output_sequences(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaa3e8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 10), dtype=int32, numpy=\n",
       "array([[12,  8,  1, ..., 10, 11,  3],\n",
       "       [12,  9,  6, ...,  6, 11,  2],\n",
       "       [12,  8,  2, ...,  2, 11,  2],\n",
       "       ...,\n",
       "       [12, 10,  8, ...,  2, 11,  4],\n",
       "       [12,  2,  2, ...,  3, 11,  3],\n",
       "       [12,  8,  9, ...,  8, 11,  3]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da4c4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use functional API to cerate model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfa8ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embedding_size = 64\n",
    "decoder_embedding_size = 64\n",
    "lstm_units = 256\n",
    "\n",
    "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "encoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(INPUT_CHARS)+1,\n",
    "    output_dim=encoder_embedding_size)(encoder_input)\n",
    "\n",
    "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(\n",
    "    lstm_units, return_state=True)(encoder_embedding)\n",
    "encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(OUTPUT_CHARS)+2, \n",
    "    output_dim = decoder_embedding_size)(decoder_input)\n",
    "\n",
    "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
    "    decoder_embedding, initial_state=encoder_state) # feed initial-state like this!\n",
    "decoder_output = keras.layers.Dense(len(OUTPUT_CHARS)+1, activation=\"softmax\")(\n",
    "    decoder_lstm_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_input, decoder_input], \n",
    "                           outputs=[decoder_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d026b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7576678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 4s 6ms/step - loss: 1.5512 - accuracy: 0.4213 - val_loss: 1.1221 - val_accuracy: 0.5710\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.6676 - accuracy: 0.7566 - val_loss: 0.2324 - val_accuracy: 0.9341\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.1189 - accuracy: 0.9737 - val_loss: 0.0361 - val_accuracy: 0.9973\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0303 - accuracy: 0.9965 - val_loss: 0.0103 - val_accuracy: 0.9999\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9999\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9999\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 8.1348e-04 - accuracy: 1.0000 - val_loss: 8.5369e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 6.1988e-04 - accuracy: 1.0000 - val_loss: 6.5864e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 4.8152e-04 - accuracy: 1.0000 - val_loss: 5.1471e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 3.8003e-04 - accuracy: 1.0000 - val_loss: 4.1373e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 3.0303e-04 - accuracy: 1.0000 - val_loss: 3.3103e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 2.4435e-04 - accuracy: 1.0000 - val_loss: 2.7054e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.9755e-04 - accuracy: 1.0000 - val_loss: 2.2403e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.6122e-04 - accuracy: 1.0000 - val_loss: 1.8309e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.3193e-04 - accuracy: 1.0000 - val_loss: 1.5210e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 1.0876e-04 - accuracy: 1.0000 - val_loss: 1.2841e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 8.9861e-05 - accuracy: 1.0000 - val_loss: 1.0681e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=20,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec2b911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 모델을 사용해 몇 가지 예측을 수행해 보죠. 이번에는 한 문자씩 예측해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb466d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "def predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = tf.fill(dims=(len(X),1), value = sos_id)\n",
    "    for index in range(max_output_length):\n",
    "        pad_size = max_output_length - Y_pred.shape[1]\n",
    "        X_decoder = tf.pad(Y_pred, [[0,0], [0,pad_size]]) # make partial input\n",
    "        Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
    "        Y_pred_next =tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
    "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=-1)\n",
    "    return ids_to_date_strs(Y_pred[:, 1:]) # disgard the first output because it's sos token!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b05da505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb09dc",
   "metadata": {},
   "source": [
    "### 세 번째 버전: TF-Addons의 seq2seq 구현 사용하기\n",
    "정확히 동일한 모델을 만들어 보죠. 하지만 TF-Addon의 seq2seq API를 사용하겠습니다. 아래 구현은 이 노트북의 위에 있는 TFA 예제와 거의 비슷합니다. 다만 모델 입력에 출력 시퀀스 길이를 지정하지 않습니다(하지만 출력 시퀀스의 길이가 매우 다른 프로젝트에서 필요하다면 쉽게 이를 추가할 수 있습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19f08e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "encoder_embedding_size = 64\n",
    "decoder_embedding_size= 64\n",
    "units = 256\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[],dtype=np.int32)\n",
    "\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS)+1, encoder_embedding_size)(encoder_inputs)\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS)+2, decoder_embedding_size) #중복!!\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(units, return_state=True) #중복!!\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()# make a sampler for training!\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(units) # lstm cell\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, \n",
    "    initial_state = encoder_state)\n",
    "\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1fccf613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "313/313 [==============================] - 6s 13ms/step - loss: 1.6187 - accuracy: 0.3915 - val_loss: 1.3750 - val_accuracy: 0.4697\n",
      "Epoch 2/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.9696 - accuracy: 0.6242 - val_loss: 0.5014 - val_accuracy: 0.8268\n",
      "Epoch 3/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2300 - accuracy: 0.9341 - val_loss: 0.0539 - val_accuracy: 0.9944\n",
      "Epoch 4/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0467 - accuracy: 0.9933 - val_loss: 0.0168 - val_accuracy: 0.9995\n",
      "Epoch 5/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0091 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.1178 - accuracy: 0.9695 - val_loss: 0.0545 - val_accuracy: 0.9905\n",
      "Epoch 9/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0104 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 7.7432e-04 - accuracy: 1.0000 - val_loss: 8.2741e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 5.8839e-04 - accuracy: 1.0000 - val_loss: 6.3893e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 4.5821e-04 - accuracy: 1.0000 - val_loss: 5.1530e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 3.6392e-04 - accuracy: 1.0000 - val_loss: 4.1014e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 2.9289e-04 - accuracy: 1.0000 - val_loss: 3.4267e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 2.3832e-04 - accuracy: 1.0000 - val_loss: 2.7661e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.9498e-04 - accuracy: 1.0000 - val_loss: 2.2936e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.6077e-04 - accuracy: 1.0000 - val_loss: 1.9063e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.3337e-04 - accuracy: 1.0000 - val_loss: 1.6315e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 1.1066e-04 - accuracy: 1.0000 - val_loss: 1.3744e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 9.2258e-05 - accuracy: 1.0000 - val_loss: 1.1526e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 7.7017e-05 - accuracy: 1.0000 - val_loss: 9.6438e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 6.4584e-05 - accuracy: 1.0000 - val_loss: 8.2743e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 5.4078e-05 - accuracy: 1.0000 - val_loss: 7.0166e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 4.5472e-05 - accuracy: 1.0000 - val_loss: 5.9425e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 3.8119e-05 - accuracy: 1.0000 - val_loss: 5.0003e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 3.2136e-05 - accuracy: 1.0000 - val_loss: 4.3258e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 2.7043e-05 - accuracy: 1.0000 - val_loss: 3.6792e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=30,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "52c4773e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d51c3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length) # only make layer\n",
    "batch_size = tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30602848",
   "metadata": {},
   "source": [
    "몇 개의 노트:\n",
    "* `GreedyEmbeddingSampler`는 `start_tokens`(디코더 시퀀스마다 sos ID를 담은 벡터)와 `end_token`(모델이 이 토큰을 출력할 때 디코더가 시퀀스 디코딩을 멈춥니다)이 필요합니다.\n",
    "* `BasicDecoder`를 만들 때 `maximum_iterations`를 설정해야 합니다. 그렇지 않으면 무한하게 반복할 수 있습니다(적어도 하나의 시퀀스에서 모델이 `end_token`을 출력하지 않는다면). 이렇게 되면 주피터 커널을 재시작해야 합니다.\n",
    "* 모든 디코더 입력이 이전 타임 스텝의 출력을 기반으로 동적으로 생성되기 때문에 디코더 입력은 더 이상 필요하지 않습니다.\n",
    "* 모델의 출력은 `final_outputs.rnn_outputs`의 소프트맥스가 아니라 `final_outputs.sample_id`입니다. 로짓 값을 얻고 싶다면 `final_outputs.sample_id`을 `final_outputs.rnn_outputs`으로 바꾸세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cabedd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8d58d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])\n",
    "### 컴파일 안하면 원래 학습된 모델 재사용 가능!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d4399cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 ms ± 958 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe263f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.2 ms ± 148 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f5266",
   "metadata": {},
   "source": [
    "### 네 번째 버전: 스케줄 샘플러를 사용하는 TF-Addons의 seq2seq 구현\n",
    "이전 모델을 훈련할 때 매 타임 스텝 _t_에서 타임 스텝 _t_-1의 타깃 토큰을 모델에게 전달합니다. 하지만 추론에서는 모델이 타임 스텝마다 이전 타깃을 얻을 수 없습니다. 대신에 이전 예측을 사용합니다. 따라서 이런 훈련과 추론 사이에 차이가 실망스러운 성능으로 이어질 수 있습니다. 이를 완화하기 위해 훈련하는 동안 타깃을 예측으로 점진적으로 바꿀 수 있습니다. 이렇게 하려면 `TrainingSampler`를 `ScheduledEmbeddingTrainingSampler`를 바꾸기만 하면 됩니다. 그리고 `sampling_probability`(디코더가 이전 타임 스텝의 타깃 대신에 이전 타임 스텝의 예측을 사용할 확률)를 점진적으로 증가시키기 위해 케라스 콜백을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c95b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = tfa.seq2seq.sampler.ScheduledEmbeddingTrainingSampler(\n",
    "    sampling_probability=0.0,\n",
    "    embedding_fn = decoder_embedding_layer)\n",
    "sampler.sampling_probability= tf.Variable(0.)\n",
    "\n",
    "\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
    "                                                 sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings,\n",
    "    initial_state=encoder_state)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                           outputs=[Y_proba])\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d884c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongho/.local/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_1_grad/Identity_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_1_grad/Identity_3:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_1_grad/Identity_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/dongho/.local/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/gradients/grad_ys_0_values:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/dongho/.local/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/Identity_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/Identity:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/basic_decoder_2/decoder/while/gradients/model_3/basic_decoder_2/decoder/while/cond_grad/Identity_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 19ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 1.8496e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 9.2833e-05 - accuracy: 1.0000 - val_loss: 1.0697e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0491 - accuracy: 0.9872 - val_loss: 0.1107 - val_accuracy: 0.9694\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0270 - accuracy: 0.9960 - val_loss: 0.0051 - val_accuracy: 0.9997\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0042 - val_accuracy: 0.9997\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 8.4628e-04 - accuracy: 1.0000 - val_loss: 5.0196e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0251 - accuracy: 0.9959 - val_loss: 0.0105 - val_accuracy: 0.9988\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0090 - val_accuracy: 0.9995\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.0018 - val_accuracy: 0.9999\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 6.2989e-04 - val_accuracy: 0.9999\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0390 - val_accuracy: 0.9948\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0172 - accuracy: 0.9982 - val_loss: 0.0101 - val_accuracy: 0.9990\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0036 - val_accuracy: 0.9997\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9997\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 0.9999\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0114 - val_accuracy: 0.9987\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0069 - val_accuracy: 0.9994\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0028 - val_accuracy: 0.9998\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9996\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0116 - val_accuracy: 0.9985\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0053 - val_accuracy: 0.9995\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 7.4436e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 4.9246e-04 - val_accuracy: 0.9999\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 5.2978e-04 - val_accuracy: 0.9999\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 3.6766e-04 - accuracy: 0.9999 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 6.2276e-04 - accuracy: 0.9999 - val_loss: 4.9213e-04 - val_accuracy: 0.9999\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 3.1279e-04 - accuracy: 0.9999 - val_loss: 2.5491e-04 - val_accuracy: 0.9999\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 2.9541e-04 - accuracy: 1.0000 - val_loss: 5.7908e-04 - val_accuracy: 0.9999\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 6.0968e-05 - accuracy: 1.0000 - val_loss: 4.4757e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 5.6491e-04 - accuracy: 0.9999 - val_loss: 7.9118e-04 - val_accuracy: 0.9999\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 2.2230e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.6919e-04 - accuracy: 1.0000 - val_loss: 9.4082e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 8.4726e-05 - accuracy: 1.0000 - val_loss: 6.6443e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 5.0067e-05 - accuracy: 1.0000 - val_loss: 5.3825e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 9.7760e-04 - accuracy: 0.9998 - val_loss: 1.3394e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 6.3235e-04 - accuracy: 0.9999 - val_loss: 5.5655e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 4.2840e-05 - accuracy: 1.0000 - val_loss: 3.7152e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 2.8821e-05 - accuracy: 1.0000 - val_loss: 2.8009e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 2.2025e-05 - accuracy: 1.0000 - val_loss: 2.2213e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.7545e-05 - accuracy: 1.0000 - val_loss: 1.9854e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.4730e-05 - accuracy: 1.0000 - val_loss: 1.5160e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.1921e-05 - accuracy: 1.0000 - val_loss: 7.5309e-05 - val_accuracy: 0.9999\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 2.6745e-04 - accuracy: 0.9999 - val_loss: 2.6641e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 3.2946e-05 - accuracy: 1.0000 - val_loss: 7.2429e-05 - val_accuracy: 0.9999\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.3474e-05 - accuracy: 1.0000 - val_loss: 1.1320e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "def update_sampling_probability(epoch, logs):\n",
    "    proba = min(1.0, epoch / (n_epochs - 10))\n",
    "    sampler.sampling_probability.assign(proba)\n",
    "    pass\n",
    "\n",
    "sampling_probability_cb = keras.callbacks.LambdaCallback(\n",
    "    on_epoch_begin=update_sampling_probability) # set lambda callback like this!\n",
    "\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=n_epochs,\n",
    "                    validation_data=([X_valid, X_valid_decoder], Y_valid),\n",
    "                    callbacks=[sampling_probability_cb],\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e8b38",
   "metadata": {},
   "source": [
    "추론에서도 `GreedyEmbeddingSampler`를 사용해 앞에서와 동일한 작업을 수행할 수 있습니다. 하지만 완성도를 높이기 위해 `SampleEmbeddingSampler`를 사용하겠습니다. 토큰 ID를 찾기 위해 모델 출력에 argmax를 적용하는 대신 로짓 출력에서 랜덤하게 토큰 ID를 샘플링하는 것만 다르고 거의 동일합니다. 텍스트를 생성하는 작업에 유용합니다. `softmax_temperature` 매개변수는 세익스피어와 같은 텍스트를 생성했을 때와 같은 목적을 가집니다(이 매개변수 값이 높을수록 더 랜덤한 텍스트가 생성됩니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d58fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_temperature = tf.Variable(1.)\n",
    "\n",
    "inferance_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer,\n",
    "    softmax_temperature=softmax_temperature)\n",
    "\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length)\n",
    "batch_size = tf.shape(encoder_inputs)[:1] # 동적으로 할당!!\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "\n",
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a1d95aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creative_predict_date_strs(date_strs, temperature=1.0):\n",
    "    softmax_temperature.assign(temperature) # assign value to tf.var\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe988951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "88a7273b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"],\n",
    "                           temperature=5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36d918",
   "metadata": {},
   "source": [
    "### 다섯 번째 버전: TFA seq2seq, 케라스 서브클래싱 API, 어텐션 메커니즘 사용하기\n",
    "이 문제의 시퀀스는 꽤 짧지만 긴 시퀀스를 처리하려면 어텐션 메커니즘을 사용해야 할 것입니다. 직접 어텐션 메커니즘을 구현할 수 있지만 TF-Addons에 있는 구현을 사용하는 것이 더 간단하고 효율적입니다. 케라스 서브클래싱 API를 사용해서 만들어 보죠.\n",
    "\n",
    "**경고**: 텐서플로 버그([이슈](https://github.com/tensorflow/addons/issues/1153) 참조) 때문에 즉시 실행 모드(eager mode)에서 `get_initial_state()` 메서드가 실패합니다. 따라서 지금은 `call()` 메서드에서 `tf.function()`을 자동으로 호출하는 (따라서 그래프 모드로 실행하는) 케라스 서브클래싱 API를 사용해야 합니다.\n",
    "\n",
    "이 구현에서는 간단하게 만들기 위해 다시 `TrainingSampler`를 사용합니다(하지만 `ScheduledEmbeddingTrainingSampler`를 사용해 쉽게 바꿀 수 있습니다). 추론에는 `GreedyEmbeddingSampler`를 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49dad40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateTranslation(keras.models.Model):\n",
    "    def __init__(self, units=128, encoder_embedding_size=32,\n",
    "                 decoder_embedding_size=32, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(INPUT_CHARS) + 1,\n",
    "            output_dim=encoder_embedding_size)\n",
    "        self.encoder = keras.layers.LSTM(units,\n",
    "                                         return_sequences=True,\n",
    "                                         return_state=True)\n",
    "        self.decoder_embedding = keras.layers.Embedding(\n",
    "            input_dim=len(OUTPUT_CHARS) + 2,\n",
    "            output_dim=decoder_embedding_size)\n",
    "        self.attention = tfa.seq2seq.LuongAttention(units)\n",
    "        decoder_inner_cell = keras.layers.LSTMCell(units)\n",
    "        self.decoder_cell = tfa.seq2seq.AttentionWrapper(\n",
    "            cell=decoder_inner_cell,\n",
    "            attention_mechanism=self.attention)\n",
    "        output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.decoder_cell,\n",
    "            sampler=tfa.seq2seq.sampler.TrainingSampler(),\n",
    "            output_layer=output_layer)\n",
    "        self.inference_decoder = tfa.seq2seq.BasicDecoder(\n",
    "            cell=self.decoder_cell,\n",
    "            sampler=tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "                embedding_fn=self.decoder_embedding),\n",
    "            output_layer=output_layer,\n",
    "            maximum_iterations=max_output_length)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        encoder_input, decoder_input = inputs\n",
    "        encoder_embeddings = self.encoder_embedding(encoder_input)\n",
    "        encoder_outputs, encoder_state_h, encoder_state_c = self.encoder(\n",
    "            encoder_embeddings,\n",
    "            training=training)\n",
    "        encoder_state = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "        self.attention(encoder_outputs,\n",
    "                       setup_memory=True)\n",
    "        \n",
    "        decoder_embeddings = self.decoder_embedding(decoder_input)\n",
    "\n",
    "        decoder_initial_state = self.decoder_cell.get_initial_state(\n",
    "            decoder_embeddings)\n",
    "        decoder_initial_state = decoder_initial_state.clone(\n",
    "            cell_state=encoder_state)\n",
    "        \n",
    "        if training:\n",
    "            decoder_outputs, _, _ = self.decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                training=training)\n",
    "        else:\n",
    "            start_tokens = tf.zeros_like(encoder_input[:, 0]) + sos_id\n",
    "            decoder_outputs, _, _ = self.inference_decoder(\n",
    "                decoder_embeddings,\n",
    "                initial_state=decoder_initial_state,\n",
    "                start_tokens=start_tokens,\n",
    "                end_token=0)\n",
    "\n",
    "        return tf.nn.softmax(decoder_outputs.rnn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc7a7c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 13:26:09.008230: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce GTX 1070\" frequency: 1784 num_cores: 15 environment { key: \"architecture\" value: \"6.1\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 2097152 shared_memory_size_per_multiprocessor: 98304 memory_size: 7768375296 bandwidth: 256256000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/313 [============================>.] - ETA: 0s - loss: 2.1431 - accuracy: 0.2309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 13:26:15.093913: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce GTX 1070\" frequency: 1784 num_cores: 15 environment { key: \"architecture\" value: \"6.1\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 2097152 shared_memory_size_per_multiprocessor: 98304 memory_size: 7768375296 bandwidth: 256256000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 20ms/step - loss: 2.1431 - accuracy: 0.2309 - val_loss: 2.1167 - val_accuracy: 0.2285\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.7654 - accuracy: 0.3641 - val_loss: 2.2690 - val_accuracy: 0.2212\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.4464 - accuracy: 0.4766 - val_loss: 1.2961 - val_accuracy: 0.5399\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.3513 - accuracy: 0.5112 - val_loss: 1.2234 - val_accuracy: 0.5457\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.1866 - accuracy: 0.5488 - val_loss: 1.1684 - val_accuracy: 0.5486\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.1640 - accuracy: 0.5502 - val_loss: 1.1550 - val_accuracy: 0.5498\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.2302 - accuracy: 0.5342 - val_loss: 3.8607 - val_accuracy: 0.1853\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.2678 - accuracy: 0.5362 - val_loss: 5.2446 - val_accuracy: 0.0605\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.1614 - accuracy: 0.5582 - val_loss: 1.1342 - val_accuracy: 0.5696\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.1357 - accuracy: 0.5719 - val_loss: 3.3359 - val_accuracy: 0.2607\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.0964 - accuracy: 0.5770 - val_loss: 1.1684 - val_accuracy: 0.5883\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.8514 - accuracy: 0.6292 - val_loss: 0.8371 - val_accuracy: 0.6420\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.7151 - accuracy: 0.6813 - val_loss: 0.9171 - val_accuracy: 0.6754\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.5079 - accuracy: 0.7732 - val_loss: 0.5973 - val_accuracy: 0.7628\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3582 - accuracy: 0.8543 - val_loss: 0.4459 - val_accuracy: 0.8243\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2458 - accuracy: 0.9090 - val_loss: 0.2107 - val_accuracy: 0.9214\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2228 - accuracy: 0.9220 - val_loss: 0.1961 - val_accuracy: 0.9251\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1434 - accuracy: 0.9416 - val_loss: 0.1432 - val_accuracy: 0.9377\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1310 - accuracy: 0.9430 - val_loss: 0.1365 - val_accuracy: 0.9460\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1098 - accuracy: 0.9503 - val_loss: 0.1593 - val_accuracy: 0.9245\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0962 - accuracy: 0.9593 - val_loss: 0.1023 - val_accuracy: 0.9642\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0883 - accuracy: 0.9793 - val_loss: 0.0491 - val_accuracy: 0.9977\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0478 - accuracy: 0.9942 - val_loss: 0.0405 - val_accuracy: 0.9955\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0603 - accuracy: 0.9906 - val_loss: 0.0316 - val_accuracy: 0.9991\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0348 - accuracy: 0.9962 - val_loss: 0.0214 - val_accuracy: 0.9998\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9999\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0235 - accuracy: 0.9976 - val_loss: 0.0109 - val_accuracy: 0.9999\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0950 - accuracy: 0.9844 - val_loss: 0.0172 - val_accuracy: 0.9993\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9999\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0659 - accuracy: 0.9889 - val_loss: 0.1248 - val_accuracy: 0.9781\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0126 - accuracy: 0.9990 - val_loss: 0.0061 - val_accuracy: 0.9999\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9999\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.1240 - accuracy: 0.9790 - val_loss: 0.0093 - val_accuracy: 0.9995\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.0037 - val_accuracy: 0.9999\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = DateTranslation()\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit([X_train, X_train_decoder], Y_train, epochs=50,\n",
    "                     validation_data=([X_valid, X_valid_decoder], Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "54c0e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs_v2(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    X_decoder = tf.zeros(shape=(len(X), max_output_length), dtype=tf.int32)\n",
    "    Y_probas = model.predict([X, X_decoder])\n",
    "    Y_pred = tf.argmax(Y_probas, axis=-1)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ade99a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 13:30:57.782160: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"NVIDIA GeForce GTX 1070\" frequency: 1784 num_cores: 15 environment { key: \"architecture\" value: \"6.1\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 2097152 shared_memory_size_per_multiprocessor: 98304 memory_size: 7768375296 bandwidth: 256256000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_predict_date_strs_v2([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40998ae",
   "metadata": {},
   "source": [
    "TF-Addons에는 몇 가지 흥미로운 기능이 있습니다:\n",
    "* 추론에 `BasicDecoder` 대신 `BeamSearchDecoder`를 사용하면 가장 높은 확률의 문자를 출력하는 대신 디코더가 몇 개의 후보 중에서 가장 가능성 있는 시퀀스만 유지합니다(자세한 내용은 책 16장을 참고하세요).\n",
    "* 입력이나 타깃 시퀀스의 길이가 매우 다르면 마스크를 설정하거나 `sequence_length`를 지정합니다.\n",
    "* `ScheduledEmbeddingTrainingSampler` 보다 더 유연한 `ScheduledOutputTrainingSampler`을 사용하여 타임 스텝 _t_의 출력을 타임 스텝 _t_+1에 주입하는 방법을 결정합니다. 기본적으로 argmax로 ID를 찾지 않고 임베딩 층에 통과시켜 출력을 셀에 바로 주입합니다. 또는 `next_inputs_fn` 함수를 지정하여 셀 출력을 다음 스텝의 입력으로 변환할 수 있습니다.\n",
    "\n",
    "*바로 주입하면 임베딩의 확률이 나옴!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbaa87",
   "metadata": {},
   "source": [
    "## 11.\n",
    "_연습문제: 최신 언어 모델 중 하나(예를 들어 BERT)로 세익스피어가 쓴 것 같은 텍스트를 생성해보세요._\n",
    "최신 언어 모델을 사용하는 가장 간단한 방법은 허깅 페이스의 오픈 소스 라이브러리인 [트랜스포머스](https://huggingface.co/transformers/)를 사용하는 것입니다. 이 라이브러리는 자연어 처리(NLP)를 위한 최신 신경망 구조(BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet 등)와 사전훈련된 모델을 많이 제공합니다. 텐서플로와 파이토치를 지원합니다. 무엇보다도 사용하기 매우 쉽습니다.\n",
    "먼저 사전훈련된 모델을 로드해 보죠. 이 예제에서 추가적인 언어 모델(입력 임베딩에 연결된 가중치를 가진 선형층)을 위에 얹은 OpenAI의 GPT 모델을 사용하겠습니다. 모델을 임포트하고 사전훈련된 가중치를 로드합니다(약 445MB의 데이터가 `~/.cache/torch/transformers`에 다운로드됩니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "addbc660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cfa4c451934e2b854133c2e1e2bca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/656 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c904a7f09f14fe4b5d63714839f3d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 13:38:36.620703: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "All model checkpoint layers were used when initializing TFOpenAIGPTLMHeadModel.\n",
      "\n",
      "All the layers of TFOpenAIGPTLMHeadModel were initialized from the model checkpoint at openai-gpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFOpenAIGPTLMHeadModel\n",
    "\n",
    "model = TFOpenAIGPTLMHeadModel.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e80546bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2fd2191d1044b68742d42c898fd27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ebf148ead4f9c874026d837aa00a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/448k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "from transformers import OpenAIGPTTokenizer\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1f2a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"This royal throne of kings, this sceptred isle\"\n",
    "encoded_prompt = tokenizer.encode(prompt_text,\n",
    "                                  add_special_tokens=False,\n",
    "                                  return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "653c3eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187]], dtype=int32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "393ffb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = 5\n",
    "length = 40\n",
    "\n",
    "generated_sequences = model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    do_sample=True,\n",
    "    max_length=length + len(encoded_prompt[0]),\n",
    "    temperature=1.0,\n",
    "    top_k = 0,\n",
    "    top_p = 0.9,\n",
    "    repetition_penalty=1.0,\n",
    "    num_return_sequences=num_sequences,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2d0e3997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 50), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   544,  3478, 13762,   239,   547,  1158,   980,  1120,\n",
       "         1816,   547,  6818,   485,  2150,   618,   239,   487,   961,\n",
       "          510,   485,  2150,   246,   618,   620,   525,   606,   635,\n",
       "          589,  1578,  1557,   481,  6404,   239,   244, 40477,   244,\n",
       "          525,   544,  1849,   240,   244],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   240,   645,   600,   812,  1168,   510,   481,   638,\n",
       "          485,  1759,   547, 26478,   793,   500,   481,  2264,   498,\n",
       "         2820,   240,   620,  1311,   617,   481, 17287,   498,   481,\n",
       "         2185,   498,   589,   481,  8319,   498,   618,   535,   850,\n",
       "          240,  1048,   249,   485,  3079],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   509, 11764,   562,  1272,   498,   524, 15583,   240,\n",
       "          568,  5210,   589,   618,  1338,  5454,   240,   246, 38619,\n",
       "         3100,   240,   961,   524,   905,  8844,  1175,   702,   754,\n",
       "         1820,   240,  1698,   498,   481,  1709,   487,   948,   500,\n",
       "          616,  2235,   239,   481,  4425],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   239, 40477,   244,   568,   240,  3076,  1662,   240,\n",
       "          244,   481,   618,  2318,   240,   244,   246,  1119,   509,\n",
       "         3105,   485,   510,   240,   246,  8343,   485,   580,   481,\n",
       "        39145, 30675,   498,   589,   481, 10472,   240,   481,  8323,\n",
       "         2185,   498,   481,  6903,   239],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   485,   580,   239,   507,   636,  1443,   580,   246,\n",
       "        16841,   498,   936, 22250,   240,   525, 22405,   488,   618,\n",
       "          239,   256, 40477,   256,   620,   525,   535,   507,   240,\n",
       "          674,   240,   256,  8071,   603,   239,   256,   861,   589,\n",
       "          525,   606,   880,   694,   822]], dtype=int32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "51c400c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this royal throne of kings, this sceptred isle is perfectly legitimate. my father has always known my intention to become king. he wanted me to become a king so that we could all hold onto the throne. \" \n",
      " \" that is true, \"\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle, if they will give me the way to start my labour here in the hall of david, so far from the citadel of the lord of all the glory of king's day, am i to learn\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle was ideal for many of his peers, but unlike all king hordal, a mongol count, wanted his most loyal men by their power, instead of the others he took in this order. the threat\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle. \n",
      " \" but, dear friends, \" the king added, \" a love was born to me, a longing to be the mightiest of all the lords, the noble lord of the realm.\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle to be. it would soon be a reign of immorality, that tyrant and king.'\n",
      "'so that's it, then,'sparhawk said.'after all that we've been through\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sequence in generated_sequences:\n",
    "    text = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n",
    "    print(text)\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba2ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HOML]",
   "language": "python",
   "name": "conda-env-HOML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
