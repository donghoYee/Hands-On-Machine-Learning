{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1a38ac",
   "metadata": {},
   "source": [
    "# 층 정규화를 사용하는 사용자 정의 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48955bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d787669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 15:37:54.099472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.125957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.126131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.126771: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-08 15:37:54.127368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.127517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.127645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.501483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.501653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.501783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 15:37:54.501891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7408 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[2.       ],\n",
       "        [5.3333335]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[0.6666667],\n",
       "        [1.5555555]], dtype=float32)>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.,2.,3.],[4.,5.,7.]])\n",
    "tf.nn.moments(a, axes=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975444d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name=\"alpha\", shape=batch_input_shape[-1:], initializer='ones', dtype=tf.float32)\n",
    "        self.betha = self.add_weight(name=\"betha\", shape=batch_input_shape[-1:], initializer='zeros', dtype=tf.float32)\n",
    "        \n",
    "        super().build(batch_input_shape)\n",
    "        pass\n",
    "    \n",
    "    def call(self, X):\n",
    "        mean, dis = tf.nn.moments(X, axes=-1, keepdims=True) # keepdims = True -> N X 1 array\n",
    "        std = tf.sqrt(dis)\n",
    "        return self.alpha * (X - mean) / (std + 1e-6) + self.betha\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list())\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"alpha\": self.alpha, \"betha\":self.betha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c9ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_normalization = MyLayerNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_a = my_normalization(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa13a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[-1.2247434 ,  0.        ,  1.2247434 ],\n",
       "       [-1.0690444 , -0.26726118,  1.3363051 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090eaf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e8598c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[ 0.0000000e+00],\n",
       "        [-1.1920929e-07]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[0.99999756],\n",
       "        [0.99999857]], dtype=float32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.moments(norm_a, axes=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f87c7c",
   "metadata": {},
   "source": [
    "# 사용자 정의 훈련 반복을 사용해 패션 MNIST 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0678c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ffe0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6910122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d832ba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b93f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710dabdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 28, 28)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c6da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n",
    "    MyLayerNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n",
    "    MyLayerNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebab2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154164a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result()) for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration <= total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "997ea38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size= 100\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer1 = keras.optimizers.Nadam(learning_rate = 0.01)\n",
    "optimizer2 = keras.optimizers.Nadam(learning_rate = 0.001)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.Accuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "419afad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch 1/20\n",
      "45000/45000 - mean: 1.3175 - accuracy: 0.6340\n",
      "validation: loss 1.2215467691421509 accuracy 0.6700666546821594\n",
      "\n",
      " epoch 2/20\n",
      "45000/45000 - mean: 1.1593 - accuracy: 0.6784\n",
      "validation: loss 1.4261993169784546 accuracy 0.6229333281517029\n",
      "\n",
      " epoch 3/20\n",
      "45000/45000 - mean: 1.1275 - accuracy: 0.6921\n",
      "validation: loss 1.0662237405776978 accuracy 0.7019333243370056\n",
      "\n",
      " epoch 4/20\n",
      "45000/45000 - mean: 1.1361 - accuracy: 0.6826\n",
      "validation: loss 1.0653562545776367 accuracy 0.7075999975204468\n",
      "\n",
      " epoch 5/20\n",
      "45000/45000 - mean: 1.1535 - accuracy: 0.6801\n",
      "validation: loss 1.1222496032714844 accuracy 0.7170666456222534\n",
      "\n",
      " epoch 6/20\n",
      "45000/45000 - mean: 1.1033 - accuracy: 0.6925\n",
      "validation: loss 1.1769856214523315 accuracy 0.6540666818618774\n",
      "\n",
      " epoch 7/20\n",
      "45000/45000 - mean: 1.1042 - accuracy: 0.6889\n",
      "validation: loss 1.147184133529663 accuracy 0.6760666370391846\n",
      "\n",
      " epoch 8/20\n",
      "45000/45000 - mean: 1.0270 - accuracy: 0.7124\n",
      "validation: loss 1.0247336626052856 accuracy 0.7282666563987732\n",
      "\n",
      " epoch 9/20\n",
      "45000/45000 - mean: 1.0755 - accuracy: 0.6936\n",
      "validation: loss 0.9491486549377441 accuracy 0.741599977016449\n",
      "\n",
      " epoch 10/20\n",
      "45000/45000 - mean: 1.1498 - accuracy: 0.6828\n",
      "validation: loss 0.9308798313140869 accuracy 0.7282666563987732\n",
      "\n",
      " epoch 11/20\n",
      "45000/45000 - mean: 0.7875 - accuracy: 0.7681\n",
      "validation: loss 0.7394523024559021 accuracy 0.7771999835968018\n",
      "\n",
      " epoch 12/20\n",
      "45000/45000 - mean: 0.7152 - accuracy: 0.7857\n",
      "validation: loss 0.6891104578971863 accuracy 0.8004666566848755\n",
      "\n",
      " epoch 13/20\n",
      "45000/45000 - mean: 0.7125 - accuracy: 0.7924\n",
      "validation: loss 0.6979973912239075 accuracy 0.7955333590507507\n",
      "\n",
      " epoch 14/20\n",
      "45000/45000 - mean: 0.6840 - accuracy: 0.8001\n",
      "validation: loss 0.6672393083572388 accuracy 0.8096666932106018\n",
      "\n",
      " epoch 15/20\n",
      "45000/45000 - mean: 0.6689 - accuracy: 0.8063\n",
      "validation: loss 0.660267174243927 accuracy 0.81086665391922\n",
      "\n",
      " epoch 16/20\n",
      "45000/45000 - mean: 0.6625 - accuracy: 0.8045\n",
      "validation: loss 0.6542937159538269 accuracy 0.8090000152587891\n",
      "\n",
      " epoch 17/20\n",
      "45000/45000 - mean: 0.6622 - accuracy: 0.8051\n",
      "validation: loss 0.647062361240387 accuracy 0.8073333501815796\n",
      "\n",
      " epoch 18/20\n",
      "45000/45000 - mean: 0.6699 - accuracy: 0.7965\n",
      "validation: loss 0.6536863446235657 accuracy 0.8092666864395142\n",
      "\n",
      " epoch 19/20\n",
      "45000/45000 - mean: 0.6459 - accuracy: 0.8046\n",
      "validation: loss 0.6826215982437134 accuracy 0.7954000234603882\n",
      "\n",
      " epoch 20/20\n",
      "45000/45000 - mean: 0.6329 - accuracy: 0.8090\n",
      "validation: loss 0.6535017490386963 accuracy 0.8062666654586792\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"\\n epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        if(epoch <= 10):\n",
    "            optimizer1.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        else:\n",
    "            optimizer2.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, np.argmax(y_pred, axis=1))\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()\n",
    "    \n",
    "    ## val\n",
    "    y_val_pred = model(X_val)\n",
    "    main_loss = tf.reduce_mean(loss_fn(y_val, y_val_pred))\n",
    "    loss = tf.add_n([main_loss] + model.losses)\n",
    "    accuracy = keras.metrics.Accuracy()(np.argmax(y_val_pred, axis=1), y_val)\n",
    "    \n",
    "    print(\"\\nvalidation: loss {} accuracy {}\".format(loss, accuracy.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "703ac90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f08a9828c40>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b347190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model(X_test[:2]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31122626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HOML]",
   "language": "python",
   "name": "conda-env-HOML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
