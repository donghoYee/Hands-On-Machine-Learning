{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d9fba3",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bb707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f1027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5958931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 13:10:56.194352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.219020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.219188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.219887: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-10 13:10:56.220511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.221090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.222759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.573861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.574032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.574168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 13:10:56.574311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1250 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "codings_size = 30\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(28* 28, activation=\"sigmoid\"),\n",
    "    keras.layers.Reshape([28, 28])\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(150, activation=\"selu\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ce29e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397558a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299bac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_images(images, n_cols=None):\n",
    "    n_cols = n_cols or len(images)\n",
    "    n_rows = (len(images) - 1) // n_cols + 1\n",
    "    if images.shape[-1] == 1:\n",
    "        images = np.squeeze(images, axis=-1)\n",
    "    plt.figure(figsize=(n_cols, n_rows))\n",
    "    for index, image in enumerate(images):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d41b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom train loop\n",
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"training epoch: \", epoch)\n",
    "        for X_batch in dataset: # get each batch like this!\n",
    "            # training discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_images = generator(noise)\n",
    "            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size) # use 2d label!\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            \n",
    "            # training  generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        plot_multiple_images(generated_images, 8)                     # not shown\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b55bbea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_gan(gan, dataset, batch_size, codings_size, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c0fc5",
   "metadata": {},
   "source": [
    "### DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78040a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size=100\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(7*7*128, input_shape=[codings_size]), # no activation?\n",
    "    keras.layers.Reshape([7, 7, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(32, kernel_size=5, strides=2, padding=\"same\", activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\"), # use tanh for activation?\n",
    "    keras.layers.Reshape([28, 28]),\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\", activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\", activation = keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d94dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3924fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train * 2 -1\n",
    "X_test_scaled = X_test * 2 -1\n",
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X_train_scaled).shuffle(1000)\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a3499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 13:12:09.284600: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_grad_input_ops.cc:384 : NOT_FOUND: No algorithm worked!  Error messages:\n",
      "  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 3: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n",
      "  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\n",
      "in tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Exception encountered when calling layer \"conv2d_transpose_2\" (type Conv2DTranspose).\n\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n  Profiling failure on CUDNN engine 3: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())' [Op:Conv2DBackpropInput]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32, 7, 7, 128), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodings_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m(gan, dataset, batch_size, codings_size, n_epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch \u001b[38;5;129;01min\u001b[39;00m dataset: \u001b[38;5;66;03m# get each batch like this!\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# training discriminator\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     noise \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(shape\u001b[38;5;241m=\u001b[39m[batch_size, codings_size])\n\u001b[0;32m----> 9\u001b[0m     generated_images \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     X_fake_and_real \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([generated_images, X_batch], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0.\u001b[39m]] \u001b[38;5;241m*\u001b[39m batch_size \u001b[38;5;241m+\u001b[39m [[\u001b[38;5;241m1.\u001b[39m]] \u001b[38;5;241m*\u001b[39m batch_size) \u001b[38;5;66;03m# use 2d label!\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/backend.py:5720\u001b[0m, in \u001b[0;36mconv2d_transpose\u001b[0;34m(x, kernel, output_shape, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   5717\u001b[0m   strides \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m strides\n\u001b[1;32m   5719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dilation_rate \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m-> 5720\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5721\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5722\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5723\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5724\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m dilation_rate[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m dilation_rate[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Exception encountered when calling layer \"conv2d_transpose_2\" (type Conv2DTranspose).\n\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n  Profiling failure on CUDNN engine 3: UNKNOWN: CUDNN_STATUS_EXECUTION_FAILED\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())'\n  Profiling failure on CUDNN engine 0: UNKNOWN: CUDNN_STATUS_INTERNAL_ERROR\nin tensorflow/stream_executor/cuda/cuda_dnn.cc(4159): 'cudnnConvolutionBackwardData( cudnn.handle(), alpha, filter_.handle(), filter_data.opaque(), output_nd_.handle(), output_data.opaque(), conv_.handle(), ToConvBackwardDataAlgo(algo), scratch_memory.opaque(), scratch_memory.size(), beta, input_nd_.handle(), input_data.opaque())' [Op:Conv2DBackpropInput]\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(32, 7, 7, 128), dtype=float32)"
     ]
    }
   ],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caea115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HOML]",
   "language": "python",
   "name": "conda-env-HOML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
